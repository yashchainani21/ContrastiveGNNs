{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c34ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37880d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fp_CNN_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, fp_dim = 2048, hidden_channels = (64, 128), embed_dim = 256, proj_dim = 120, use_projection = True, batchnorm_safe = True):\n",
    "        super().__init__()\n",
    "        c1, c2 = hidden_channels\n",
    "\n",
    "        # convolution stack\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1, out_channels = c1, kernel_size = 5, padding = 2),\n",
    "            nn.BatchNorm1d(num_features = c1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv1d(in_channels = c1, out_channels = c2, kernel_size = 5, padding = 2),\n",
    "            nn.BatchNorm1d(num_features = c2),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.AdaptiveMaxPool1d(1), # collapse length to 1\n",
    "            )\n",
    "\n",
    "        # encoder head\n",
    "        self.fc = nn.Linear(in_features = c2, out_features = embed_dim)\n",
    "\n",
    "        # projection head\n",
    "        self.use_projection = use_projection\n",
    "        self.batchnorm_safe = batchnorm_safe\n",
    "        if self.use_projection:\n",
    "            if self.batchnorm_safe:\n",
    "                # LayerNorm works with batch_size=1\n",
    "                norm_layer = nn.LayerNorm(embed_dim)\n",
    "            else:\n",
    "                # BatchNorm1d is better if you always train with batch_size > 1\n",
    "                norm_layer = nn.BatchNorm1d(embed_dim)\n",
    "\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.Linear(embed_dim, embed_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                norm_layer,\n",
    "                nn.Linear(embed_dim, proj_dim),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, fp_dim] or [B, 1, fp_dim]\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1) # add channel dim, [B, 1, fp_dim]\n",
    "\n",
    "        h = self.conv(x).squeeze(-1) # [B, c2, 1] -> [B, c2]\n",
    "        g = F.normalize(self.fc(h), dim = -1) # [B, embed_dim], normalized embedding\n",
    "\n",
    "        if self.use_projection:\n",
    "            z = F.normalize(self.proj(g), dim = -1)\n",
    "            return g, z\n",
    "        else:\n",
    "            return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be343c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPZFingerprints(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for loading precomputed fingerprints from a .npz file.\n",
    "    \"\"\"\n",
    "    def __init__(self, npz_path: str, dtype = torch.float32, normalize = False):\n",
    "        z = np.load(npz_path, mmap_mode='r')\n",
    "        self.fps = z[\"fps\"]\n",
    "        self.labels = z[\"labels\"]\n",
    "        self.N, self.D = self.fps.shape\n",
    "        self.dtype = dtype\n",
    "        self.normalize = normalize\n",
    "        if normalize:\n",
    "            # compute per-feature mean/std if requested\n",
    "            arr = np.asarray(self.fps, dtype=np.float32)\n",
    "            self.mean = arr.mean(axis=0)\n",
    "            self.std = arr.std(axis=0) + 1e-8 # avoid div-by-zero\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x = np.asarray(self.fps[idx], dtype=np.float32)\n",
    "        if self.normalize:\n",
    "            x = (x - self.mean) / self.std\n",
    "        y = int(self.labels[idx])\n",
    "        return torch.as_tensor(x, dtype=self.dtype), torch.as_tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223bdcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Supervised Contrastive Learning Loss (Khosla et al., 2020)\n",
    "    Operates on normalized embeddings; no augmentations needed.\n",
    "    All samples sharing the same label in a batch are considered positives.\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.tau = temperature\n",
    "\n",
    "    def forward(self, z: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        z: [B, d] normalized projections\n",
    "        labels: [B] int labels\n",
    "        \"\"\"\n",
    "        B = z.size(0)\n",
    "        sim = z @ z.t() / self.tau  # cosine sims since z normalized\n",
    "\n",
    "        # masks\n",
    "        eye = torch.eye(B, dtype=torch.bool, device=z.device)\n",
    "        labels = labels.view(-1, 1)\n",
    "        pos_mask = (labels == labels.t()) & (~eye)   # same-class pairs\n",
    "        all_mask = ~eye                              # all except self\n",
    "\n",
    "        # log prob over all others\n",
    "        logits = sim\n",
    "        denom = torch.logsumexp(logits.masked_fill(~all_mask, -1e9), dim=1, keepdim=True)\n",
    "        log_prob = logits - denom\n",
    "\n",
    "        # average over positives per anchor\n",
    "        pos_log_prob = (pos_mask * log_prob).sum(1) / (pos_mask.sum(1) + 1e-9)\n",
    "        loss = -pos_log_prob.mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cadd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weighted_sampler(labels_np: np.ndarray):\n",
    "    \"\"\"\n",
    "    Balances batches by inverse class frequency\n",
    "    \"\"\"\n",
    "    counts = np.array([np.sum(labels_np == 0), np.sum(labels_np == 1)], dtype=np.float64)\n",
    "    w_per_class = 1.0 / (counts + 1e-12)\n",
    "    weights = np.array([w_per_class[y] for y in labels_np], dtype=np.float64)\n",
    "    return WeightedRandomSampler(weights=torch.from_numpy(weights).double(),\n",
    "                                 num_samples=len(labels_np), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b02f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed: int):\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86025c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_val(val_loader, encoder, device):\n",
    "    encoder.eval()\n",
    "    all_g, all_y = [], []\n",
    "    \n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        _, _ = encoder(xb) if encoder.use_projection else encoder(xb)\n",
    "        g = encoder(xb)[0] if encoder.use_projection else encoder(xb)  # [B, embed_dim]\n",
    "        all_g.append(g.cpu())\n",
    "        all_y.append(yb)\n",
    "\n",
    "    X = torch.cat(all_g, dim=0).numpy()\n",
    "    y = torch.cat(all_y, dim=0).numpy()\n",
    "\n",
    "    # simple linear probe\n",
    "    clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(X)[:,1]\n",
    "\n",
    "    auprc = average_precision_score(y, y_pred)\n",
    "    return auprc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    seed_all(args.seed)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() and not args.cpu else \"cpu\")\n",
    "\n",
    "    train_ds = NPZFingerprints(args.train_npz, dtype=torch.float32, normalize=args.normalize)\n",
    "    val_loader = None\n",
    "    if args.val_npz and os.path.exists(args.val_npz):\n",
    "        val_ds = NPZFingerprints(args.val_npz, dtype=torch.float32, normalize=args.normalize)\n",
    "        val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    # weighted sample to ensure PKSs appear regularly in batches\n",
    "    labels_np = train_ds.labels.astype(np.int64)\n",
    "    sampler = make_weighted_sampler(labels_np) if args.balance else None\n",
    "    train_loader = DataLoader(train_ds,\n",
    "                              batch_size=args.batch_size,\n",
    "                              sampler=sampler,\n",
    "                              shuffle=(sampler is None),\n",
    "                              num_workers=args.num_workers,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    # model & loss\n",
    "    encoder = fp_CNN_Encoder(fp_dim = args.fp_dim,\n",
    "                             hidden_channels = (args.c1, args.c2),\n",
    "                             embed_dim = args.embed_dim,\n",
    "                             proj_dim = args.proj_dim,\n",
    "                             use_projection = args.use_projection,\n",
    "                             batchnorm_safe = args.batchnorm_safe).to(device)\n",
    "\n",
    "    criterion = SupConLoss(temperature=args.temperature).to(device)\n",
    "    optimizer = torch.optim.AdamW(encoder.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "    os.makedirs(args.out_dir, exist_ok=True)\n",
    "    best_monitor = -1.0\n",
    "    patience = 0\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        encoder.train()\n",
    "        epoch_loss, steps = 0.0, 0\n",
    "        t0 = time.time()\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n",
    "                # no augmentations\n",
    "                _, z = encoder(xb) \n",
    "                loss = criterion(z, yb)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if args.grad_clip > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(encoder.parameters(), args.grad_clip)\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "\n",
    "            epoch_loss += loss.item(); steps += 1\n",
    "\n",
    "        epoch_loss /= max(1, steps)\n",
    "        msg = f\"[Epoch {epoch:03d}] train_supcon={epoch_loss:.4f} time={time.time()-t0:.1f}s\"\n",
    "\n",
    "        if val_loader is not None:\n",
    "            auprc = evaluate_val(val_loader, encoder, device)\n",
    "            msg += f\" val_AUPRC={auprc:.4f}\"\n",
    "        print(msg)\n",
    "\n",
    "    torch.save({\"encoder\": encoder.state_dict(), \"args\": vars(args)},\n",
    "               os.path.join(args.out_dir, \"last_encoder.pt\"))\n",
    "    print(f\"Saved to {args.out_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCTS_py311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
